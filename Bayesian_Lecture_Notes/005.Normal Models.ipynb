{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1f6c68-91c4-40a2-a63e-e0b2c8e75aec",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\"> Normal Models\n",
    "\n",
    "\n",
    "Consider $n$ independent and identically distributed (**i.i.d.**) Normal random variables $Y_1, Y_2, \\dots, Y_n$ with range of $Y$ is $\\mathscr{A}_Y = (-\\infty,\\infty)$, that is the entire real line. \n",
    "\n",
    "$$\n",
    "Y_i \\sim \\text{Normal}(\\mu,\\sigma^2), \\quad \\mu \\in (-\\infty, \\infty); \\quad  \\sigma^2 \\in (0,\\infty)$$ \n",
    "\n",
    "\n",
    "Probability Density Function of $Y$ is,\n",
    "\n",
    "$$f(Y_i \\mid \\mu,\\sigma^2) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\,e^{-\\frac{(y_i-\\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "Also, if $X= \\sum_{i=1}^{n} y_i$  represents the number of occurances of the event, then $X$ follows a Poisson distribution with parameter $n ~\\theta$\n",
    "\n",
    "### <font color=\"darkblue\"> **Likelihood Function**\n",
    "\n",
    "The likelihood function for this model is\n",
    "\n",
    "$$\n",
    "P(y | \\mu,\\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sigma\\sqrt{2 \\pi}} \\exp\\left(-\\frac{(y_i - \\mu)^2}{2 \\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(y | \\mu,\\sigma^2) = \\left[\\frac{1}{\\sigma\\sqrt{2 \\pi}}\\right]^n \\exp\\left(-\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2 \\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Here $\\exp( )$ refers to the exponential function $e^{( \\,)} $\n",
    "\n",
    "---\n",
    "\n",
    "## <font color=\"darkgreen\"> Model - I - Unknown Mean; Known Variance\n",
    "\n",
    "We assume that the variance parameter $\\sigma^2$ is known and only unknown parameter is $\\mu$\n",
    "\n",
    "### <font color=\"darkblue\"> **Prior**\n",
    "\n",
    "Let us consider a **conjugate prior** for the parameter $\\mu$ whose space is $(-\\infty, \\infty)$, a continuous random variable in the entire real line.  A **Normal distribution** could be a natural choice for modeling the **mean $\\mu$** of a Normal distribution in a Bayesian context\n",
    "\n",
    "That is, let $\\mu \\sim \\text{Normal}(\\eta,\\tau^2)$  where $\\eta \\in (-\\infty, \\infty); \\quad  \\tau^2 \\in (0,\\infty)$\n",
    "\n",
    "So, PDF of $\\mu$ is\n",
    "\n",
    "$$p(\\mu)=\\frac{1}{\\tau\\sqrt{2\\pi}}\\,e^{-\\frac{(\\mu-\\eta)^2}{2\\tau^2}}$$ with the range  $\\mathscr{A}_\\mu=(-\\infty,\\infty)$ \n",
    "\n",
    "---\n",
    "### <font color=\"darkblue\"> **Posterior Distribution via Bayes' Theorem**\n",
    "\n",
    "Applying Bayes' theorem:\n",
    "\n",
    "$$\n",
    "\\pi(\\mu \\mid \\mathbf{Y},\\sigma^2) = \\frac{\\mathscr{L}(\\mu|\\mathbf{Y},\\sigma^2) \\, p(\\mu)}{m(\\mathbf{Y})}$$ where $m(\\mathbf{Y})$ is called the marginal likelihood\n",
    "\n",
    "The denominator is \n",
    "\n",
    "$$m(\\mathbf{Y}) = \\int_{-\\infty}^{\\infty}\\frac{1}{\\tau\\sqrt{2\\pi}}\\,\\exp\\left(-\\frac{(\\mu-\\eta)^2}{2\\tau^2}\\right) \\left[\\frac{1}{\\sigma\\sqrt{2 \\pi }}\\right]^n \\exp\\left(-\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2 \\sigma^2}\\right)\\, d\\mu $$\n",
    "\n",
    "\n",
    "$$\\implies m(\\mathbf{Y}) = \\left[\\frac{1}{\\sigma\\sqrt{2 \\pi }}\\right]^n\\,\\frac{1}{\\tau\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty}\\exp\\left(-\\frac{(\\mu-\\eta)^2}{2\\tau^2}\\right) \\exp\\left(-\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2 \\sigma^2}\\right) \\, d\\mu \\,\\cdots\\cdots\\cdots\\,(1)$$\n",
    "\n",
    "\n",
    "Consider the second term in the above integrand,\n",
    "\n",
    "$$\\frac{1}{2\\sigma^2} \\sum_{i=1}^{n}(y_i - \\mu)^2 = \\sum_{i=1}^{n}(y_i - \\bar{y}+\\bar{y}-\\mu)^2$$\n",
    "\n",
    "$$=\\sum_{i=1}^{n}\\left[(y_i-\\bar{y})^2+(\\bar{y}-\\mu)^2-2(y_i-\\bar{y})(\\bar{y}-\\mu)\\right]$$\n",
    "\n",
    "$$=\\sum_{i=1}^{n}(y_i-\\bar{y})^2+n(\\bar{y}-\\mu)^2-2(\\bar{y}-\\mu)\\sum_{i=1}^{n}(y_i-\\bar{y})$$\n",
    "\n",
    "$$=\\sum_{i=1}^{n}(y_i-\\bar{y})^2+n(\\bar{y}-\\mu)^2$$ since $(\\bar{y}-\\mu)\\sum_{i=1}^{n}(y_i-\\bar{y})=0$\n",
    "\n",
    "$(1)$ becomes, $$ m(\\mathbf{Y}) = \\left[\\frac{1}{\\sigma\\sqrt{2 \\pi }}\\right]^n\\,\\frac{1}{\\tau\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty}\\exp\\left(-\\frac{(\\mu-\\eta)^2}{2\\tau^2}\\right)  \\exp\\left(-\\frac{\\sum_{i=1}^{n}(y_i-\\bar{y})^2+n(\\bar{y}-\\mu)^2}{2 \\sigma^2}\\right) $$\n",
    "\n",
    "That is,\n",
    "\n",
    "$$ m(\\mathbf{Y}) = \\left[\\frac{1}{\\sigma\\sqrt{2 \\pi}}\\right]^n\\,\\frac{1}{\\tau\\sqrt{2\\pi}} \\exp\\left(-\\frac{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}{2 \\sigma^2}\\right)\\int_{-\\infty}^{\\infty}\\exp\\left(-[\\frac{(\\mu-\\eta)^2}{2\\tau^2}+\\frac{n(\\bar{y}-\\mu)^2}{2 \\sigma^2}]\\right) \\, d\\mu \\,\\cdots\\cdots\\cdots\\,(2)$$\n",
    "\n",
    "Consider the exponential term\n",
    "\n",
    "$$\\frac{(\\mu-\\eta)^2}{\\tau^2}+\\frac{n(\\bar{y}-\\mu)^2}{\\sigma^2}$$\n",
    "\n",
    "$$=\\frac{1}{\\tau^2}(\\mu^2+\\eta^2-2\\mu\\tau)+\\frac{n}{\\sigma^2}(\\bar{y}^2+\\mu^2-2\\mu\\bar{y})$$\n",
    "\n",
    "$$=\\mu^2(\\frac{n}{\\sigma^2}+\\frac{1}{\\tau^2})-2\\mu(\\frac{n\\bar{y}}{\\sigma^2}+\\frac{\\eta}{\\tau^2})+(\\frac{n\\bar{y}^2}{\\sigma^2}+\\frac{\\eta^2}{\\tau^2})$$\n",
    "\n",
    "$$=A\\left[\\mu^2-2\\mu \\frac{B}{A}+\\frac{C}{A}\\right]$$ where $A=\\frac{n}{\\sigma^2}+\\frac{1}{\\tau^2}; \\,B=(\\frac{n\\bar{y}}{\\sigma^2}+\\frac{\\eta}{\\tau^2}); \\,C=(\\frac{n\\bar{y}^2}{\\sigma^2}+\\frac{\\eta^2}{\\tau^2})$\n",
    "\n",
    "Use the method of completing squre for the above quadratic equation in $\\mu$\n",
    "\n",
    "$$=A\\left[(\\mu-\\frac{B}{A})^2-\\frac{B^2}{A^2}+\\frac{C}{A}\\right]$$\n",
    "\n",
    "$$=A(\\mu-\\frac{B}{A})^2-\\frac{B^2}{A}+C$$\n",
    "\n",
    "$$=\\frac{(\\mu-\\frac{B}{A})^2}{\\frac{1}{A}}+(C-\\frac{B^2}{A})$$\n",
    "\n",
    "\n",
    "Hence, $(2)$ becomes,\n",
    "\n",
    "$$ m(\\mathbf{Y}) = \\left[\\frac{1}{\\sigma\\sqrt{2 \\pi}}\\right]^n\\,\\frac{1}{\\tau\\sqrt{2\\pi}} \\exp\\left(-\\frac{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}{2 \\sigma^2}\\right) \\exp\\left[-\\frac{1}{2}(C-\\frac{B^2}{A})\\right]\\int_{-\\infty}^{\\infty}\\exp\\left[-\\frac{(\\mu-\\frac{B}{A})^2}{2\\frac{1}{A}}\\right]\\,d\\mu \\cdots\\cdots\\cdots (3)$$\n",
    "\n",
    "\n",
    "$$m(\\mathbf{Y}) = \\left[\\frac{1}{\\sigma\\sqrt{2 \\pi}}\\right]^n\\,\\frac{1}{\\tau\\sqrt{2\\pi}} \\exp\\left(-\\frac{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}{2 \\sigma^2}\\right) \\exp\\left[-\\frac{1}{2}(C-\\frac{B^2}{A})\\right]\\sqrt{2\\pi\\frac{1}{A}}\\cdots\\cdots\\cdots (4)$$\n",
    "\n",
    "It can be observed that $(3)$ provides the quantities in the numerator of the posterior distribution $\\mu$ of $\\pi(\\mu |\\mathbf{Y},\\sigma^2)$ except for the integral operation\n",
    "\n",
    "That is, the numerator of $\\pi(\\mu |\\mathbf{Y},\\sigma^2)$ is \n",
    "\n",
    "$$\\left[\\frac{1}{\\sigma\\sqrt{2 \\pi}}\\right]^n\\,\\frac{1}{\\tau\\sqrt{2\\pi}} \\exp\\left(-\\frac{\\sum_{i=1}^{n}(y_i-\\bar{y})^2}{2 \\sigma^2}\\right) \\exp\\left[-\\frac{1}{2}(C-\\frac{B^2}{A})\\right]\\exp\\left[-\\frac{(\\mu-\\frac{B}{A})^2}{2\\frac{1}{A}}\\right]\\cdots\\cdots\\cdots (5)$$\n",
    "\n",
    "Simplifying $\\frac{(5)}{(4)}$ gives the posterior, \n",
    "\n",
    "$$\\pi(\\mu |\\mathbf{Y},\\sigma^2) =\\frac{1}{\\sqrt{2\\pi\\frac{1}{A}}} \\exp\\left[-\\frac{(\\mu-\\frac{B}{A})^2}{2\\frac{1}{A}}\\right]$$ with $\\mathscr{A}_{\\mu} \\in (-\\infty,\\,\\infty)$\n",
    "\n",
    "This is the Normal PDF with mean $\\frac{B}{A}$ and variance $\\frac{1}{A}$\n",
    "\n",
    "$$\\implies\\, \\mu |\\mathbf{Y},\\sigma^2 \\sim \\,\\text{Normal} (\\frac{B}{A},\\frac{1}{A})$$\n",
    "\n",
    "where, $\\frac{B}{A}=\\frac{\\frac{1}{\\frac{\\sigma^2}{n}}\\bar{y}+\\frac{1}{\\tau^2}\\eta}{\\frac{1}{\\frac{\\sigma^2}{n}}+\\frac{1}{\\tau^2}}$ \n",
    "\n",
    "or, \n",
    "\n",
    "$\\frac{B}{A}=\\frac{w_1}{w_1+w_2}\\bar{y}+\\frac{w_2}{w_1+w_2}\\eta$, weighted mean of data precision $(w_1=\\frac{1}{\\frac{\\sigma^2}{n}})$  and prior precision $(w_2=\\frac{1}{\\tau^2})$\n",
    "\n",
    "and \n",
    "\n",
    "$\\frac{1}{A}=\\frac{1}{\\frac{1}{\\frac{\\sigma^2}{n}}\n",
    "+\\frac{1}{\\tau^2}}$\n",
    "\n",
    "\n",
    "Hence, if the sample is drawn from a Normal distribution with known population variance $\\sigma^2$ and the prior for the mean parameter $\\mu$ is a Normal distribution then the posterior is also a Normal distribution, an example for conjugate prior approach. Following provides the summary,\n",
    "\n",
    "$$Y_i \\sim \\text{Normal}(\\mu,\\sigma^2)$$ it is assumed that $\\sigma^2$ is known\n",
    "\n",
    "$$\\mu \\sim \\text{Normal}(\\eta,\\tau^2)$$\n",
    "\n",
    "$$\\mu |\\mathbf{Y},\\sigma^2 \\sim \\,\\text{Normal} (\\frac{B}{A},\\frac{1}{A})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c16db-a809-4eb6-b14a-73d6fdf6fb47",
   "metadata": {},
   "source": [
    "## <font color=\"darkgreen\"> Model - II - Known Mean; Unknown Variance\n",
    "\n",
    "<font color=\"darkred\"> **Scheme I (modeling with $\\sigma^2$)**\n",
    "\n",
    "We assume that the mean parameter $\\mu$ is known and only unknown parameter is $\\sigma^2$\n",
    "\n",
    "For convenience, let $\\theta=\\sigma^2$ so that likelihood will be \n",
    "\n",
    "$$\n",
    "P(y | \\mu,\\theta) = \\left[\\frac{1}{\\sqrt{2 \\pi\\theta}}\\right]^n \\exp\\left(-\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2 \\theta}\\right)\n",
    "$$\n",
    "\n",
    "### <font color=\"darkblue\"> **Prior**\n",
    "\n",
    "Let us consider a **conjugate prior** for the parameter $\\theta$ whose space is $(0, \\infty)$, a continuous random variable in the positive real line.  An **Inverse-Gamma distribution** could be a natural choice for modeling the **variance $\\theta$** of a Normal distribution.\n",
    "\n",
    "That is, $\\theta \\sim \\text{IG}(\\alpha,\\beta)$  where $\\alpha,\\,\\beta  \\in (0, \\infty)$\n",
    "\n",
    "PDF of $\\theta$ is\n",
    "\n",
    "$$p(\\theta)=\\frac{\\beta^\\alpha}{\\Gamma{\\alpha}}\\,\\theta^{-(\\alpha+1)}\\,e^{-\\frac{\\beta}{\\theta}}$$ with the range  $\\mathscr{A}_\\theta=(0,\\infty)$ \n",
    "\n",
    "---\n",
    "### <font color=\"darkblue\"> **Posterior Distribution via Bayes' Theorem**\n",
    "\n",
    "Applying Bayes' theorem:\n",
    "\n",
    "$$\n",
    "\\pi(\\theta \\mid \\mathbf{Y},\\mu) = \\frac{\\mathscr{L}(\\theta|\\mathbf{Y},\\mu) \\, p(\\theta)}{m(\\mathbf{Y})}$$ where $m(\\mathbf{Y})$ is called the marginal likelihood\n",
    "\n",
    "The denominator is \n",
    "\n",
    "$$m(\\mathbf{Y})=\\int_{\\mathscr{A}_\\theta}\\left[\\frac{1}{\\sqrt{2\\pi\\theta}}\\right]^n \\exp\\left(-\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2 \\theta}\\right)\\frac{\\beta^\\alpha}{\\Gamma{\\alpha}}\\,\\theta^{-(\\alpha+1)}\\,e^{-\\frac{\\beta}{\\theta}}\\,d\\theta$$\n",
    "\n",
    "\n",
    "$$=\\left[\\frac{1}{\\sqrt{2\\pi\\theta}}\\right]^n\\frac{\\beta^\\alpha}{\\Gamma{\\alpha}}\\int_0^{\\infty} \\exp\\left(-\\frac{1}{\\theta}\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}\\right)\\,\\theta^{-(\\alpha+1)}\\,e^{-\\frac{\\beta}{\\theta}}\\,d\\theta$$\n",
    "\n",
    "\n",
    "$$=k\\int_0^{\\infty} [\\frac{1}{\\theta}]^{\\frac{n}{2}}\\exp\\left(-\\frac{1}{\\theta}\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}\\right)\\,\\theta^{-(\\alpha+1)}\\,e^{-\\frac{\\beta}{\\theta}}\\,d\\theta\\,\\,$$ where $k=\\left[\\frac{1}{\\sqrt{2\\pi}}\\right]^n\\frac{\\beta^\\alpha}{\\Gamma{\\alpha}}$\n",
    "\n",
    "Grouping the terms for $\\theta$,\n",
    "\n",
    "$$=k\\int_0^{\\infty} \\theta^{-(\\frac{n}{2}+\\alpha+1)}\\,\\exp\\left(-\\frac{k_1}{\\theta}\\right)\\,d\\theta\\,\\,$$ where $k_1=\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}$\n",
    "\n",
    "Comparing this with the PDF of an Inverse Gamma distribution, we get\n",
    "\n",
    "$$m(\\mathbf{Y})=k \\frac{\\Gamma(\\frac{n}{2}+\\alpha)}{k_1^{\\frac{n}{2}+\\alpha}}$$\n",
    "\n",
    "or\n",
    "\n",
    "$$m(\\mathbf{Y})=\\left[\\frac{1}{\\sqrt{2\\pi}}\\right]^n\\frac{\\beta^\\alpha}{\\Gamma{\\alpha}}\\frac{\\Gamma(\\frac{n}{2}+\\alpha)}{\\left[\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}\\right]^{\\frac{n}{2}+\\alpha}}\\cdots\\cdots\\cdots(1)$$\n",
    "\n",
    "Now the numerator is \n",
    "\n",
    "$$\\left[\\frac{1}{\\sqrt{2 \\pi}}\\right]^n \\frac{\\beta^\\alpha}{\\Gamma{\\alpha}}\\,\\exp\\left(-\\frac{\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}}{\\theta}\\right)\\,\\theta^{-(\\frac{n}{2}+\\alpha+1)}\\,\\cdots\\cdots\\cdots(2)$$\n",
    "\n",
    "Hence, $\\frac{(2)}{(1)}$ provides the posterior for $\\theta$ \n",
    "\n",
    "$$\\pi(\\theta|Y)=\\frac{{\\left[\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}\\right]^{\\frac{n}{2}+\\alpha}}}{\\Gamma(\\frac{n}{2}+\\alpha)}\\theta^{-(\\frac{n}{2}+\\alpha+1)}\\exp\\left(-\\frac{\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}}{\\theta}\\right)$$\n",
    "\n",
    "Hence, $\\theta=\\sigma^2\\sim\\text{IG}(\\frac{n}{2}+\\alpha,\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2})$\n",
    "\n",
    "Result: \n",
    "\n",
    "If the sample is drawn from a Normal distribution with known population mean $\\mu$ and the prior for the variance parameter $\\sigma^2$ is an Inverse Gamma distribution, then the posterior is also an Inverse Gamma distribution, an example for conjugate prior approach. \n",
    "\n",
    "Following provides the summary,\n",
    "\n",
    "$$Y_i \\sim \\text{Normal}(\\mu,\\sigma^2)$$ it is assumed that $\\mu$ is known\n",
    "\n",
    "$$\\sigma^2 \\sim \\text{IG}(\\alpha,\\beta)$$\n",
    "\n",
    "$$\\sigma^2 |\\mathbf{Y},\\mu \\sim \\,\\text{IG} (\\frac{n}{2}+\\alpha,\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60c836-86ce-4881-b7cb-45dba8e21c61",
   "metadata": {},
   "source": [
    "<font color=\"darkred\"> **Scheme II (modeling with $\\tau$)**\n",
    "\n",
    "Let us model with precision parameter $\\tau$ instead of variance parameter $\\sigma^2$ using the relation, $\\tau=\\frac{1}{\\sigma^2}$\n",
    "\n",
    "Then the likelihood will be \n",
    "\n",
    "$$\n",
    "P(y | \\mu,\\tau) =\\left[\\sqrt{\\frac{\\tau}{2\\pi}}\\,\\right]^n \\exp\\left(-\\tau\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}\\right)$$\n",
    "\n",
    "or\n",
    "\n",
    "$$P(y | \\mu,\\tau) =\\left[\\sqrt{\\frac{1}{2\\pi}}\\,\\right]^n \\tau^{\\frac{n}{2}}\\exp\\left(-\\tau\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}\\right)$$\n",
    "\n",
    "\n",
    "### <font color=\"darkblue\"> **Prior** \n",
    "\n",
    "Let us consider a **conjugate prior** for the parameter $\\tau$ whose space is $(0, \\infty)$, a continuous random variable in the positive real line.  A **Gamma distribution** could be a natural choice for modeling the **precision $\\tau$** of a Normal distribution.\n",
    "\n",
    "That is, $\\tau \\sim \\text{Gamma}(\\alpha,\\beta)$ where $\\alpha > 0$ is shape parameter and $\\beta>0$ is rate $=\\frac{1}{\\text{Scale}}$ parameter \n",
    "\n",
    "Then the PDF is \n",
    "$$p(\\tau)=\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\,\\exp[-\\beta\\tau] \\,\\tau^{\\alpha-1}$$ with the range  $\\mathscr{A}_\\tau=(0,\\infty)$ \n",
    "\n",
    "---\n",
    "### <font color=\"darkblue\"> **Posterior Distribution via Bayes' Theorem**\n",
    "\n",
    "Applying Bayes' theorem:\n",
    "\n",
    "$$\n",
    "\\pi(\\tau \\mid \\mathbf{Y},\\mu) = \\frac{\\mathscr{L}(\\tau|\\mathbf{Y},\\mu) \\, p(\\tau)}{m(\\mathbf{Y})}$$ where $m(\\mathbf{Y})$ is called the marginal likelihood\n",
    "\n",
    "Now the denominator is \n",
    "\n",
    "$$m(\\mathbf{Y})=\\int_{\\mathscr{A}_{\\tau}} \\mathscr{L}(\\tau|\\mathbf{Y},\\mu) \\, p(\\tau) d\\tau$$\n",
    "\n",
    "$$m(\\mathbf{Y})= \\int_0^{\\infty} \\left[\\sqrt{\\frac{1}{2\\pi}}\\,\\right]^n \\,  \\tau^{\\frac{n}{2}}\\exp\\left(-\\tau\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}\\right)\\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\,\\exp[-\\beta\\tau] \\,\\tau^{\\alpha-1}d\\tau$$\n",
    "\n",
    "\n",
    "$$=\\left[\\sqrt{\\frac{1}{2\\pi}}\\,\\right]^n \\, \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\,\\int_0^{\\infty}  \\exp\\left[-(\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}+\\beta)\\tau\\right] \\,\\tau^{\\frac{n}{2}+\\alpha-1}\\,d\\tau$$\n",
    "\n",
    "Compare the integral with a Gamma PDF, we get \n",
    "\n",
    "$$\\int_0^{\\infty}  \\exp\\left[-(\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}+\\beta)\\tau\\right] \\,\\tau^{\\frac{n}{2}+\\alpha-1}\\,d\\tau=\\frac{\\Gamma(\\frac{n}{2}+\\alpha)}{(\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}+\\beta)^{\\frac{n}{2}+\\alpha}}$$\n",
    "\n",
    "So that the denominator of $ m(\\mathbf{Y})$ becomes\n",
    "\n",
    "$$\\left[\\sqrt{\\frac{1}{2\\pi}}\\,\\right]^n \\, \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\,\\frac{\\Gamma(\\frac{n}{2}+\\alpha)}{(\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}+\\beta)^{\\frac{n}{2}+\\alpha}}\\,\\, \\cdots\\cdots\\cdots(1)$$\n",
    "\n",
    "Where as the numerator of Bayes formula is,\n",
    "\n",
    "$$\\left[\\sqrt{\\frac{1}{2\\pi}}\\,\\right]^n\\, \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\, \\tau^{\\frac{n}{2}+\\alpha-1}\\,\\exp\\left(-(\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2})\\tau\\right) \\,\\cdots\\cdots\\cdots(2)$$\n",
    "\n",
    "Hence, $\\frac{(2)}{(1)}$ provides the posterior for $\\tau$\n",
    "\n",
    "$$\\pi(\\tau|\\mathbf{Y},\\,\\mu)=\\frac{\\left[\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}\\right]^{\\frac{n}{2}+\\alpha}}{\\Gamma(\\frac{n}{2}+\\alpha)}\\tau^{\\frac{n}{2}+\\alpha-1}\\,\\exp\\left(-(\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2})\\tau\\right)$$\n",
    "\n",
    "$\\therefore \\tau|\\mathbf{Y},\\,\\mu\\,\\sim\\text{Gamma}(a,b)$ where $a=\\frac{n}{2}+\\alpha$ is the shape parameter and the rate parameter $b=\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}+\\beta$\n",
    "\n",
    "\n",
    "Result: \n",
    "\n",
    "If the sample is drawn from a Normal distribution with known population mean $\\mu$ and the prior for the precision parameter $\\tau$ is a Gamma distribution, then the posterior is also an Gamma distribution, an example for conjugate prior approach. \n",
    "\n",
    "Following provides the summary,\n",
    "\n",
    "$$Y_i \\sim \\text{Normal}(\\mu,\\tau)$$ it is assumed that $\\mu$ is known and $\\tau=\\frac{1}{\\sigma^2}$\n",
    "\n",
    "$$\\tau \\sim \\text{Gamma}(\\alpha,\\,\\beta)$$\n",
    "\n",
    "$$\\tau \\sim \\text{Gamma}(\\frac{n}{2}+\\alpha,\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}+\\beta)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c024230-ee07-4f0a-9886-eafbe9ff2e01",
   "metadata": {},
   "source": [
    "$$\\pi(\\tau|\\mathbf{Y},\\,\\mu)=\\frac{\\left[\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2}\\right]^{\\frac{n}{2}+\\alpha}}{\\Gamma(\\frac{n}{2}+\\alpha)}\\tau^{\\frac{n}{2}+\\alpha-1}\\,\\exp\\left(-(\\beta+\\sum_{i=1}^{n}\\frac{(y_i - \\mu)^2}{2})\\tau\\right)$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
