{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad6b15dd-7870-4e96-9f38-95f2c5e887a1",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\"> Binomial Beta Model\n",
    "\n",
    "A Bernoulli trial is a random experiment with exactly two possible outcomes: typically \"success\" (with probability $\\theta$) and \"failure\" \n",
    "(with probability $1-\\theta$). Each trial is independent of others.\n",
    "\n",
    "**Examples**\n",
    "\n",
    "1. Quality Control in Manufacturing: Each light bulb tested is either **defective (failure) or non-defective (success)**.\n",
    "\n",
    "1. Customer Purchase Decision: A customer either makes a **purchase (success) or does not (failure)** during a store visit.\n",
    "\n",
    "1. Medical Test Result: A medical test result is either **positive (success) or negative (failure)**, indicating the presence of a condition.\n",
    "\n",
    "---\n",
    "\n",
    "Consider $n$ independent and identically distributed (**i.i.d.**) Bernoulli random variables $Y_1, Y_2, \\dots, Y_n$\n",
    "\n",
    "$$\n",
    "Y_i \\sim \\text{Bernoulli}(\\theta), \\quad \\theta \\in (0,1) \\quad  Y_i \\in \\{0,1\\}$$ \n",
    "\n",
    "Hence the range of $Y$ is $\\mathscr{A}_Y = \\{0,1\\}$ and that of the parameter $\\theta$ is $(0,1)$ or equivalently $0 < \\theta < 1$\n",
    "\n",
    "Each $Y_i$ takes values in with probability mass function:\n",
    "\n",
    "$$P(Y_i = y_i \\mid \\theta) = \\theta^{y_i} (1 - \\theta)^{1 - y_i}$$\n",
    "\n",
    "When you perform $n$ independent Bernoulli trials, the **sum of successes** across these trials follows a Binomial distribution. \n",
    "Specifically, if $X= \\sum_{i=1}^{n} y_i$  represents the number of successes, then $X$ follows a Binomial distribution \n",
    "\n",
    "Then the Probability Mass Funtion (PMF) of $X|\\theta$ is \n",
    "\n",
    "$$P[X = x]=\\binom{n}{x} \\theta^x (1-\\theta)^{n-x}$$ where $\\quad \\theta \\in (0,1) \\quad  X \\in \\{0,1,2\\cdots \\cdots, n\\}$ or $\\mathscr{A}_X = \\{0,1,2\\cdots \\cdots, n\\}$\n",
    "\n",
    "\n",
    "The aim of statistical inference is to make conclusions about a population based on a sample of data. Given a sample, it aims to estimate unknown parameters (such as the population mean or proportion) and assess the uncertainty around these estimates. Statistical inference uses methods like point estimation, confidence intervals, and hypothesis testing to draw valid conclusions and make decisions based on the data.\n",
    "\n",
    "---\n",
    "\n",
    "In the context of a Binomial proportion, Bayesian statistical inference aims to estimate the proportion of successes in a population, given a sample. Using Bayes' theorem, prior beliefs about the proportion are updated with observed data to produce a posterior distribution for the proportion, capturing uncertainty and incorporating prior knowledge into the estimate.\n",
    "\n",
    "The **Beta distribution** is a natural choice for modeling the **Binomial proportion** in a Bayesian context because it is a **conjugate prior** for the Binomial likelihood. This means that when you update a Beta prior with Binomial data, the resulting posterior distribution is also a Beta distribution \n",
    "\n",
    "Additionally, the Beta distribution is flexible and defined on the interval [0, 1], which aligns perfectly with the possible values of a proportion. The shape of the Beta distribution can be easily adjusted using its parameters (α and β) to reflect different prior beliefs about the proportion \n",
    "\n",
    "---\n",
    "\n",
    "## <font color=\"darkgreen\"> **Likelihood Function**\n",
    "\n",
    "Given $n$ observations, the likelihood function of $\\theta$  is $$\\mathscr{L}(\\theta)=\\binom{n}{x} \\theta^x (1-\\theta)^{n-x}$$\n",
    "\n",
    "## <font color=\"darkblue\"> **Beta Prior for $\\theta$**\n",
    "\n",
    "Assume a **Beta prior** distribution for the parameter $\\theta$:\n",
    "\n",
    "$$\n",
    "\\theta \\sim \\text{Beta}(a, b)\n",
    "$$\n",
    "\n",
    "The Probability Density Function (PDF) of the Beta distribution is:\n",
    "\n",
    "$$\n",
    "P(\\theta) = \\frac{\\theta^{a - 1} (1 - \\theta)^{b - 1}}{B(a, b)}\n",
    "$$\n",
    "\n",
    "where $B(a, b)$ is the **Beta function**:\n",
    "\n",
    "$$\n",
    "B(a, b) = \\int_0^1 t^{a - 1} (1 - t)^{b - 1} \\, dt\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## <font color=\"darkblue\"> **Posterior Distribution via Bayes' Theorem**\n",
    "\n",
    "Applying Bayes' theorem:\n",
    "\n",
    "$$\n",
    "\\pi(\\theta \\mid \\mathbf{X}) = \\frac{\\mathscr{L}(\\theta) \\, P(\\theta)}{m(\\mathbf{X})}$$ where $m(\\mathbf{X})$ is called the marginal likelihood given by \n",
    "\n",
    "$$\n",
    "m(\\mathbf{X}) = \\int_0^1 L(\\theta) \\, P(\\theta) \\, d\\theta = \\int_0^1 \\frac{\\theta^{x + a - 1} (1 - \\theta)^{n - x + b - 1}}{B(a, b)} \\, d\\theta\n",
    "$$\n",
    "\n",
    "Now, The **numerator** is:\n",
    "\n",
    "$$\n",
    "\\mathscr{L}(\\theta) \\, P(\\theta) = \\left[ \\theta^x (1 - \\theta)^{n - x} \\right] \\left[ \\frac{\\theta^{a - 1} (1 - \\theta)^{b - 1}}{B(a, b)} \\right]\n",
    "$$\n",
    "\n",
    "Simplifying:\n",
    "\n",
    "$$\n",
    "\\mathscr{L}(\\theta) \\, P(\\theta) = \\frac{\\theta^{x + a - 1} (1 - \\theta)^{n - x + b - 1}}{B(a, b)}\n",
    "$$\n",
    "\n",
    "Whereas the integral in the **denominator** \n",
    "\n",
    "$$\n",
    "m(\\mathbf{X}) = \\int_0^1 L(\\theta) \\, P(\\theta) \\, d\\theta = \\int_0^1 \\frac{\\theta^{x + a - 1} (1 - \\theta)^{n - x + b - 1}}{B(a, b)} \\, d\\theta\n",
    "$$ can be recognized as as the Beta function $B(x + a, n - x + b)$\n",
    "\n",
    "$$\n",
    "m(\\mathbf{X}) = \\frac{B(x + a, n - x + b)}{B(a, b)}\n",
    "$$\n",
    "\n",
    "Thus, the **posterior distribution** is:\n",
    "\n",
    "$$\n",
    "\\pi(\\theta \\mid \\mathbf{X}) = \\frac{L(\\theta) \\, P(\\theta)}{p(\\mathbf{X})} = \\frac{\\theta^{x + a - 1} (1 - \\theta)^{n - x + b - 1}}{B(x + a, n - x + b)}\n",
    "$$\n",
    "\n",
    "This is the PDF of a **Beta distribution**:\n",
    "\n",
    "$$\n",
    "\\theta \\mid \\mathbf{X} \\sim \\text{Beta}(x + a, n - x + b)\n",
    "$$\n",
    "\n",
    "### <font color=\"darkblue\"> **Final Notes**\n",
    "\n",
    "- The **posterior distribution** is a Beta distribution.\n",
    "  \n",
    "- The **updated parameters** are:\n",
    "  - **Posterior shape parameter**: $a' = x + a$\n",
    "  - **Posterior rate parameter**: $b' = n - x + b$\n",
    "    \n",
    "- This demonstrates that the **Beta distribution is a conjugate prior** for the proportion parameter in the Binomial likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21e8bd-1c77-4019-accc-6947f4ab4908",
   "metadata": {},
   "source": [
    "## <font color=\"darkblue\">**More about the prior**\n",
    "\n",
    "Beta distribution with two shape parameters $a$ and $b$ forms a conjugate prior for the proportion parameter $\\theta$ of Binomial distribution. This can be understood from the form of posterior distribution which is also a Beta distribution with parameters $x+a$ and $n-x+b$. This convenience provides quick and direct summary for the parameter $\\theta$ from the posterior with the sample information $X$\n",
    "\n",
    "---\n",
    "\n",
    "## <font color=\"darkred\">**Point Estimate from the Posterior Beta distribution**\n",
    "\n",
    "### MAP \n",
    "\n",
    "The **MAP estimate** corresponds to the mode of the posterior distribution. For a **Beta distribution**, the mode is given by:\n",
    "\n",
    "$$\\hat{\\theta}_{MAP} = \\frac{x + \\alpha - 1}{n + \\alpha + \\beta - 2}$$\n",
    "\n",
    "Where:\n",
    "- $ x $ is the number of successes.\n",
    "- $ n $ is the total number of trials.\n",
    "- $ \\alpha $ and $ \\beta $ are the parameters of the Beta prior distribution.\n",
    "\n",
    "#### Conditions for the Mode:\n",
    "\n",
    "- The mode is valid for $ \\theta $ in the interval $ (0, 1) $ if $ x + \\alpha - 1 > 0 $ and $ n - x + \\beta - 1 > 0 $. Otherwise, the mode may be at the boundaries $ \\theta = 0 $ or $ \\theta = 1 $.\n",
    "\n",
    "\n",
    "### Mean:\n",
    "\n",
    "$$\\text{E}[\\theta \\mid \\mathbf{X}] = \\frac{x + a}{n + a + b}$$\n",
    "\n",
    "### Variance:\n",
    "\n",
    "$$\\text{Var}[\\theta \\mid \\mathbf{X}] = \\frac{(x + a)(n - x + b)}{(n + a + b)^2 (n + a + b + 1)}$$\n",
    "\n",
    "---\n",
    "\n",
    "It can be noted that the choice of the prior parameters $a$ and $b$ will influence these summaries and also to recall that prior parameters can help to incorporate any additional / reasonable information about the parameter beyond the available sample data. \n",
    "\n",
    "---\n",
    "# Non-informative for binomial proportion parameter\n",
    "\n",
    "## 1. Uniform Prior \n",
    "\n",
    "When no information (prior) about the parameter $\\theta$ is available, then we can assume that $\\theta$ can assume all plausible values equally likely in its space $[0,1]$; that is, it can assume any value randomly in the space\n",
    "\n",
    "For this no-information situation, we can consider a Uniform distribution in $[0,1]$ which is the Beta$(1,1)$; that is $a = 1, b = 1$\n",
    "\n",
    "\n",
    "## 2. Jeffreys Prior \n",
    "\n",
    "Also, we can consider Jeffreys prior based on Fisher Information matrix, $I(\\theta)=\\sqrt{E[-H(\\theta)]}$ where $H(\\theta)$ is the Hessian matrix of $l(\\theta)=\\text{ln}(\\mathscr{L}(\\theta))$; here, ln refers to natural logirthm (base $e$), $\\text{ln}_em$\n",
    "\n",
    "In the case of Binomial likelihood, $$\\mathscr{L}(\\theta)=\\binom{n}{x} \\theta^x (1-\\theta)^{n-x}$$ and hence,\n",
    "\n",
    "$l(\\theta) = \\text{ln}(\\mathscr{L}(\\theta))= \\text{ln}(\\binom{n}{x} \\theta^x (1-\\theta)^{n-x})$\n",
    "\n",
    "We use the properties of logirthm,\n",
    "\n",
    "$l(\\theta) = \\text{ln}\\binom{n}{x} +  \\text{ln}(\\theta^x) + \\text{ln}(1-\\theta)^{n-x}$\n",
    "\n",
    "\n",
    "$l(\\theta) = k_0 +  x ~ \\text{ln}(\\theta) + (n-x) ~ \\text{ln}(1-\\theta)$ where $k_0=\\text{ln}\\binom{n}{x}$ is a constant, independent of $\\theta$\n",
    "\n",
    "Now to get the Hessian matrix $H(\\theta)$, we shall differentiate $l(\\theta)$ twice with respect to $\\theta$\n",
    "\n",
    "$$\\frac{dl}{d\\theta}=\\frac{x}{\\theta}-\\frac{n-x}{1-\\theta}$$ (the first term in $l(\\theta)$ is constant so that its differentiation with respect to $\\theta$ becomes zero)\n",
    "\n",
    "$$ H(\\theta) = \\frac{d^2l}{d\\theta^2}=-\\frac{x}{\\theta^2}-\\frac{n-x}{(1-\\theta)^2}$$\n",
    "\n",
    "Expectation of $H(\\theta)$ is,\n",
    "\n",
    "$$ \\text{E}[H(\\theta)] = -\\frac{n\\theta}{\\theta^2}-\\frac{n-n\\theta}{(1-\\theta)^2}$$\n",
    "\n",
    "$$ \\text{E}[H(\\theta)] = -\\frac{n}{\\theta}-\\frac{n}{1-\\theta}$$\n",
    "\n",
    "$$ \\text{E}[H(\\theta)] = -n[\\frac{1-\\theta+\\theta}{\\theta(1-\\theta)}]$$\n",
    "\n",
    "$$ \\text{E}[H(\\theta)] = -n[\\frac{1}{\\theta(1-\\theta)}]$$\n",
    "\n",
    "Hence the Fisher Information matrix  $I(\\theta)=\\sqrt{E[-H(\\theta)]}$ will be \n",
    "\n",
    "$$ I(\\theta) = [n\\frac{1}{\\theta(1-\\theta)}]^{\\frac{1}{2}}$$ which is proportional to (up to the constant)\n",
    "\n",
    "\n",
    "$$ I(\\theta)  \\propto \\theta^{-\\frac{1}{2}} (1-\\theta)^{-\\frac{1}{2}}$$ \n",
    "\n",
    "$$ I(\\theta)  \\propto \\theta^{\\frac{1}{2}-1} (1-\\theta)^{\\frac{1}{2}-1}$$ \n",
    "\n",
    "The the expression in the right hand side of the above equation is similar to the Beta distribution with parameters $a = b = \\frac{1}{2}$\n",
    "\n",
    "$\\implies$ the Jeffreys prior for the Binomial proportion parameter will become Beta distribution with parameters $a = b = \\frac{1}{2}$\n",
    "\n",
    "\n",
    "# <font color=\"darkblue\"> A note on Beta Distribution (Prior)\n",
    "\n",
    "**<font color=\"darkred\"> Prior** $p(\\theta)$\n",
    "\n",
    "$$\\theta \\sim \\mathrm{Beta}(a,b)$$ $0 < \\theta <1~~ a,b > 0$\n",
    "\n",
    "\n",
    "## Originally, we had $a = b = 1$\n",
    "\n",
    "- ## <font color=\"red\">What is the rationality?\n",
    "\n",
    "## <font color=\"darkviolet\"> Versatility of Beta Distributions\n",
    "\n",
    "- Range is $(0, 1)$\n",
    "\n",
    "- Both $a, b$ are shape parameters\n",
    "\n",
    "- If $a = b = 1$, it is the Uniform random variable in $(0,1)$\n",
    "\n",
    "- Symmetric when $a = b$\n",
    "\n",
    "- When $a>b$, $\\theta$ \"near $1$\" is more probable\n",
    "\n",
    "- When $a<b$, $\\theta$ \"near $0$\" is more probable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af3beb-6c9b-47fd-a76d-29d5aef7f599",
   "metadata": {},
   "source": [
    "# <font color=\"darkred\"> A Visual Representation\n",
    "\n",
    "We can observe the useful shapes of Beta distribution that reflect many forms of the parameter in the $(0,1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc485d3-5b9b-4bd9-8ee7-e5a7c1bbcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "from scipy import stats as st\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753fea9b-67df-44e5-b900-4441c7daf48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10000\n",
    "#Uniform Prior - Vague / Flat\n",
    "a=0.5\n",
    "b=0.5\n",
    "symm=0.5\n",
    "rand_gen=st.beta.rvs(a,b,size=k)\n",
    "fig = plt.figure(figsize = (20, 8))\n",
    "plt.hist(rand_gen,alpha=0.8)\n",
    "plt.axvline(x=symm, color='r',linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d2ce61-43c0-4b53-a211-99ca8af66422",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10000\n",
    "#Jeffreys Prior\n",
    "a=0.5\n",
    "b=0.5\n",
    "symm=0.5\n",
    "rand_gen=st.beta.rvs(a,b,size=k)\n",
    "fig = plt.figure(figsize = (20, 8))\n",
    "plt.hist(rand_gen,alpha=0.8)\n",
    "plt.axvline(x=symm, color='r',linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d9583f-b4ac-43f7-b446-6c81dfb85dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10000\n",
    "#Symmetry (a, b >1)\n",
    "a=5\n",
    "b=5\n",
    "symm=0.5\n",
    "rand_gen=st.beta.rvs(a,b,size=k)\n",
    "fig = plt.figure(figsize = (20, 8))\n",
    "plt.hist(rand_gen,alpha=0.8)\n",
    "plt.axvline(x=symm, color='r',linewidth=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0162e72-1003-4cb7-bdb1-22451cd5b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mirror Image\n",
    "k=10000\n",
    "a=6\n",
    "b=0.3\n",
    "symm=0.5\n",
    "fig = plt.figure(figsize = (20, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "rand_gen1=st.beta.rvs(a,b,size=k)\n",
    "plt.hist(rand_gen1,alpha=0.8)\n",
    "plt.axvline(x=symm, color='r',linewidth=4)\n",
    "plt.text(0.3, 2000, [a,b], horizontalalignment='left', fontsize=30, color='green', weight='bold')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "rand_gen2=st.beta.rvs(b,a,size=k)\n",
    "plt.hist(rand_gen2,alpha=0.8)\n",
    "plt.axvline(x=symm, color='r',linewidth=4)\n",
    "plt.text(0.3, 2000, [b,a], horizontalalignment='left', fontsize=30, color='green', weight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55551b00-0d46-417d-b21e-b7ed8e767cd7",
   "metadata": {},
   "source": [
    "## <font color=\"darkblue\">**Inference from Posterior**\n",
    "\n",
    "We have already observed that the mean and variance from the Posterior Beta distribution are \n",
    "\n",
    "$$\\text{E}[\\theta \\mid \\mathbf{X}] = \\frac{x + a}{n + a + b}$$\n",
    "\n",
    "$$\\text{Var}[\\theta \\mid \\mathbf{X}] = \\frac{(x + a)(n - x + b)}{(n + a + b)^2 (n + a + b + 1)}$$\n",
    "\n",
    "---\n",
    "\n",
    "Now to obtain **interval estimate** for the parameter $\\theta$ we use the following idea\n",
    "\n",
    "A $100(1-\\alpha)\\%$ **Credible Interval** for $\\theta$ is an interval $[a_1, a_2]$ such that the probability that $\\theta$ **lies** in the interval is $1-\\alpha$; that is, \n",
    "\n",
    "$$Pr(\\theta \\in [a_1, a_2])=1-\\alpha$$\n",
    "\n",
    "$$\\implies Pr(\\theta \\in [a_1, a_2])=\\int_{a_1}^{a_2} \\pi(\\theta|X) d\\theta$$\n",
    "\n",
    "If an appropriate / reasonable conjugate prior parameters $a, b$ are chosen then the above limits $a_1$ and $a_2$ can be calculated as the inverse CDF of Beta (posterior) distribution\n",
    "\n",
    "This may lack a closed form approach in obtaining the limits, we may refer to any computational environment to make use of the built in functions for CDF of a distribution (here, a Beta distribution)\n",
    "\n",
    "For example we may refer to python librabry *scipy* for this; following code may provide the necessary steps\n",
    "\n",
    "```python\n",
    "from scipy.stats import beta\n",
    "beta.ppf(p, x+a, n-x+b)\n",
    "```\n",
    "- where $p$ is the required value $(0 < p < 1)$ for finding the quantile (inverse CDF)\n",
    "\n",
    "- $x+a, n-x+b$  are the parameters of the Beta (posterior) distribution\n",
    "\n",
    "$p$ is chosen based on the required size $1-\\alpha$ of the Credible interval; that is\n",
    "\n",
    "1. p = $\\frac{\\alpha}{2}$ for the lower limit $a_1$\n",
    "2. p =  $1-\\frac{\\alpha}{2}$ for the upper limit $a_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b697f10-8f57-4409-bf5c-935e1127609d",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\"> Predictive Distribution\n",
    "\n",
    "Bayesian model allows to obtain distribution about unseen data in the light of information contained in the posterior of the parameter $\\theta$ exist in the original likelihood\n",
    "\n",
    "\n",
    "## <font color=\"darkred\"> Predictive information about \"New Data\"\n",
    "\n",
    "- Observe a data $X$ parameterised by $\\theta$\n",
    "\n",
    "- Construct prior for $\\theta$\n",
    "\n",
    "- Obtain posterior $\\theta|X$\n",
    "\n",
    "- **Interested to know the probability distribution about \"unseen data $Y$\"**\n",
    "\n",
    "$$p(Y|X) = \\int_{\\theta}p(Y|\\theta)\\pi(\\theta|X)~d\\theta$$\n",
    "\n",
    "- $p$ refers to the pdf of $Y$ parameterised by $\\theta$ (same as $X$)\n",
    "\n",
    "- $\\pi$ refers to Posterior of $\\theta$\n",
    "\n",
    "## <font color=\"darkviolet\"> For Binomial Case\n",
    "\n",
    "1. Originally the data was a Binomial with $x$ and $n$\n",
    "\n",
    "1. The Prior was Beta with parameters $a$ and $b$\n",
    "\n",
    "1. The Posterior was Beta with parameters $x+a$ and $n-x+b$\n",
    "\n",
    "Hence Posterior predictive for an unseen environment is out of a new trial, say $m$ number times, what is the distribution of then number of successes $y$\n",
    "\n",
    "So again the likelihood $\\mathcal{L}[\\theta|Y]$ or PMF $f(Y|\\theta)$ is from\n",
    "\n",
    "$$Y|\\theta = \\mathrm{Binomial}(m, \\theta)$$\n",
    "\n",
    "## <font color=\"red\"> But information for $\\theta$ is no longer prior but the posterior\n",
    "\n",
    "$$\\therefore p(Y|X)=\\int_{\\theta}p(y|\\theta)\\pi(\\theta|x)~d\\theta$$ leads to\n",
    "\n",
    "\n",
    "$$\\therefore p(Y|X)=\\int_0^1{m \\choose y} \\theta^y (1-\\theta)^{m-y} \\frac{1}{\\beta(a_1,a_2)}\\theta^{a_1-1} (1-\\theta)^{a_2-1} ~d\\theta$$\n",
    "\n",
    "where $a_1=x+a$ and $a_2=n-x+b$\n",
    "\n",
    "$$\\implies p(Y|X)=\\frac{{m \\choose y}}{\\beta(a_1,a_2)}\\int_0^1 \\theta^{y+a_1-1} (1-\\theta)^{m-y+a_2-1} ~d\\theta$$\n",
    "\n",
    "$$\\implies p(Y=y|x=x)=\\frac{{m \\choose y}}{\\beta(a_1,a_2)}\\beta(y+a_1, m-y+a_2)$$\n",
    "\n",
    "where the range for $m$ is $y=0,1,2,\\cdots\\cdots,m$\n",
    "\n",
    "## <font color=\"maroon\">**This is called Beta-Binomial Distribution**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
