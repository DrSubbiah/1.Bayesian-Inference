{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87feaa6-869b-4209-a604-54fbfd4f1ac0",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\"> Monte-Carlo Integration\n",
    "\n",
    "First let us consider a closed form solution. Let $f(x) = x^2$. Then the integration of $f(x)$ in $(1,\\,2)$ is \n",
    "\n",
    "$$\\int_1^2 f(x)\\,dx$$\n",
    "\n",
    "$$=\\int_1^2 x^2 \\,dx$$\n",
    "\n",
    "$$=[\\frac{x^3}{3}]_1^2$$\n",
    "\n",
    "$$=\\frac{8}{3}-\\frac{1}{3}$$\n",
    "\n",
    "$$\\int_1^2 x^2 \\,dx=\\frac{7}{3}\\approx 2.33\\cdots\\cdots\\cdots(1)$$\n",
    "\n",
    "Now, let us choose $k$ numbers randomly from the interval $(1, \\,2)$, square them and sum the squares. Multiply the sum by $\\frac{(2-1)}{k}$. \n",
    "\n",
    "Let $k=10$ Then a random choice of $10$ numbers in the interval $(1, \\,2)$ could be $\\{1.1642, 1.487, 1.7964, 1.3071, 1.7962,1.1329,1.8332,1.2192,1.3506,1.4702\\}$ whose\n",
    "sum of the square is $21.8446$. Then $\\frac{21.8446}{10} = 2.18446$. We can repeat this process for a larger value of $k$ and compare the **Closeness** of the result with the closed form result in $(1)$. Every time the closeness  can be observed with (1) for the better accuracy or approximation with negligible or tolerable error\n",
    "\n",
    "For example, a choice of $k=100$ has yielded a result $2.361$. It may be noted that this value need not be the same when we repeat another set of $k=100$ numbers randomly chosen from $(1, \\,2)$ \n",
    "\n",
    "## <font color=\"darkred\"> Working Rule of Monte-Carlo Integration\n",
    "\n",
    "Consider $\\int_\\text{L}^\\text{H}g(x) \\,dx$, a real valued function defined on the interval $(\\text{L},\\,\\text{H})$\n",
    "\n",
    "1. Choose $k$ points randomly from the interval $(\\text{L},\\,\\text{H})$\n",
    "\n",
    "1. Evaluate the **integrand** $g(x)$ at these points\n",
    "\n",
    "1. Compute $(\\text{H}-\\text{L})\\frac{\\sum g(x_i)}{k}$\n",
    "\n",
    "### <font color=\"darkgreen\"> Application - Summary Statistics\n",
    "\n",
    "Let us consider a continuous uniform random variable $X$ in $(5, 15)$. We need the mean of $X$. A **Closed form solution through direct integration** is \n",
    "\n",
    "$$E[X]=\\int_5^{15}x f(x) dx$$ \n",
    "\n",
    "$$=\\int_5^{15}x \\frac{1}{10} dx$$ \n",
    "\n",
    "$$=\\big[\\frac{x^2}{10\\times2}\\big]_5^{15}$$ \n",
    "\n",
    "$$=\\frac{15^2-5^2}{20}$$\n",
    "\n",
    "$$=\\frac{225-25}{20} = 10$$\n",
    "\n",
    "Alternatively, another **Closed form solution through the formula** for mean of a random variable $X \\sim \\text {Uniform(L, H)}$\n",
    "\n",
    "$$E[X]=\\frac{\\text{L+H}}{2}$$\n",
    "\n",
    "$$=\\frac{15+5}{2}=10$$\n",
    "\n",
    "\n",
    "Following *python* code is <font color=\"green\">**performing** </font> the above calculation using a Monte Carlo Integration.\n",
    "\n",
    "**Note about Uniform(a,b) in *scipy* library**\n",
    "\n",
    "In the standard form, the distribution is uniform on $[0,\\, 1]$. Using the parameters **loc $\\mu$** and **scale $\\eta$**, one obtains the uniform distribution on $[\\mu,\\, \\mu + \\eta]$.\n",
    "Here, we need to generate random numbers from $(5,\\,15)$ and hence $\\mu=5$ and $\\eta=10$\n",
    "```\n",
    "import numpy as np\n",
    "from scipy import stats as st\n",
    "L=5        #L:lower limit \n",
    "s=10        #scale\n",
    "H=L+s    #H:Upper Limit = L + scale (s)\n",
    "k=100\n",
    "a=st.uniform.rvs(loc=L,scale=s,size=k)\n",
    "b=a/10 #Evaluating the function x/10\n",
    "(H-L)*np.sum(b)/k\n",
    "```\n",
    "\n",
    "The number $(k)$ of samples can be chosen arbitrarily, but <font color=\"red\">*sufficiently large*. \n",
    "\n",
    "For example, $k=100$ in the above code yields the mean value $E[X]=10.362 \\approx 10$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7db70cd-ceff-4538-aea5-e99293428e59",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\"> Monte Carlo and Bayesian\n",
    "\n",
    "While developing a Bayesian model, it is essential to address the posterior distribution of a parameter given the data. If the posterior is tractable and can be expressed in terms of a known distribution, most summaries can be obtained using the corresponding closed-form expressions. However, if this is not the case or if a closed-form solution is not straightforward, we must explore alternative approaches\n",
    "\n",
    "<font color=\"red\">*This note provides a general overview of MCMC from a development perspective, highlighting its utilities, importance, and relevance. Additional readings on MC and MCMC can be found at the end of the material*\n",
    "\n",
    "**<span style=\"color:darkblue\">Conventional Symbols**\n",
    "\n",
    "1. $\\theta:$ Parameter (Univariate / Multivariate)\n",
    "\n",
    "1. $p(X|\\theta):$ Data Model\n",
    "\n",
    "1. $p(\\theta):$ Prior Model\n",
    "\n",
    "1. $\\pi(\\theta|X):$ Posterior Model\n",
    "\n",
    "When the posterior is available in closed form (such as when using a conjugate prior), but certain summaries cannot be expressed in closed form, simulations from the posterior $\\hat\\theta_i^{MC}$ can be used to obtain the desired summaries, such as\n",
    "\n",
    "- Posterior Mean $E(\\theta|X)=\\mathrm{mean}\\Big(\\hat\\theta_i^{MC}\\Big)$\n",
    "\n",
    "- Posterior Variance $V(\\theta|X)=\\mathrm{variance}\\Big(\\hat\\theta_i^{MC}\\Big)$\n",
    "\n",
    "- Median (any percentile)\n",
    "$\\mathrm{Med}(\\theta|X)=\\mathrm{median}\\Big(\\hat\\theta_i^{MC}\\Big)$\n",
    "\n",
    "- Probabilities involving $\\theta|X$\n",
    "\n",
    "For a plausible value 'b' about $\\theta$\n",
    "$p(\\theta|X<b)=\\mathrm{proportion}\\Big(\\hat\\theta_i^{MC}<b\\Big)$ in 10000 draws\n",
    "\n",
    "***Probability computations help to find required Bayesian credible intervals***\n",
    "\n",
    "\n",
    "<span style=\"color:darkred\">Monte Carlo (MC) methods rely heavily on simulations, and while a closed-form posterior is often essential for implementing traditional MC approaches, there are alternative Monte Carlo algorithms that can generate samples directly from more complex or non-standard posterior distributions, as commonly encountered in Bayesian analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa45cd1-ec36-4843-a439-2df573121c34",
   "metadata": {},
   "source": [
    "##<font color=\"darkgreen\"> Acceptane-Rejection Algorithm\n",
    "\n",
    "The acceptance-rejection algorithm is a Monte Carlo method used to generate samples from a target distribution by leveraging an easy-to-sample proposal distribution. It works by sampling from the proposal distribution and accepting or rejecting each sample based on a criterion that ensures the resulting samples follow the target distribution. This technique is particularly useful when the target distribution is difficult to sample from directly.\n",
    "\n",
    "**Situation:** The desired function (Target distribution)  $f(x)$ is not easy to simulate\n",
    "\n",
    "**Approach:** Propose a function (Instrumental / Candidate distribution) $g(x)$, to simulate from it directly\n",
    "\n",
    "**Requirement** $\\frac{f(x)}{g(x)}\\le M$ for all $x$\n",
    "\n",
    "**Algorithm** Two steps\n",
    "\n",
    "  1. Generate $Y \\sim g(x)$ $U \\sim U[0,1]$\n",
    "\n",
    "  1. Accept  $X = Y$ if $U \\le \\frac{f(Y)}{Mg(Y)}$ else reject Y\n",
    "\n",
    "  Repeat\n",
    "\n",
    "\n",
    "**Information**\n",
    "The candidate density can be set to 1, so instead of generating $ U $ from $U[0, 1]$, it can be generated from $U[0, M]$, where $M$ is chosen as the mode of $f(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46475025-3e85-49d4-9b84-2d8c83005587",
   "metadata": {},
   "source": [
    "## <font color=\"darkblue\"> Markov Chain Monte Carlo\n",
    "\n",
    "Monte Carlo techniques are commonly used to simulate independent and identically distributed (iid) samples, which are helpful in many probabilistic simulations. However, in certain cases, especially when dealing with complex distributions, obtaining correlated samples may be more beneficial. By transitioning to Markov Chain Monte Carlo (MCMC) methods, we can leverage a Markov Chain to generate dependent samples. This approach not only allows us to explore more complex state spaces, but also offers improved convergence properties, leading to more efficient and accurate estimations, even with high-dimensional problems\n",
    "\n",
    "\n",
    "A Markov chain is based on a simple yet powerful principle: ***the future depends only on the present, not on the past.*** In other words, the probability of an uncertain event occurring at a given instance is determined solely by its immediate preceding state, and not by any earlier instances (whether they happened or not).\n",
    "\n",
    "- For example, natural events like the weather on a given day are typically influenced by the weather of the previous day, but not by the weather from several weeks ago.\n",
    "\n",
    "- Similarly, a customer’s decision to switch to a new brand of cosmetic cream might depend on their most recent purchase, rather than earlier ones.\n",
    "\n",
    "- A fresher’s performance in a graduate course is likely to be influenced by their immediate prior schooling, rather than by their performance in earlier education stages.\n",
    "\n",
    "These types of situations can be modeled using a simple yet fascinating Markov chain (discrete).\n",
    "\n",
    "$$p(X_{n+1}=x_{n+1}|X_{n}=x_{n},X_{n-1}=x_{n-1}\\cdots X_{0}=x_{0})=p(X_{n+1}=x_{n+1}|X_{n}=x_{n})$$ where $n+1, n, n-1\\cdots 0$ indicate future, present and past respectively\n",
    "\n",
    "\n",
    "This concept is extensively utilized in Bayesian Data-Prior models. The conditional relationship between the data and the parameter allows the samples to be generated from one another, ultimately leading to a collection of samples from the desired distribution — specifically, the posterior distribution.\n",
    "\n",
    "**The essential ingredients for MCMC are: deciding where to start, determining when to stop, ensuring proper mixing of the chains, and most importantly, selecting independent samples.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25af15-5a3a-4191-bd1e-ea9900bbb872",
   "metadata": {},
   "source": [
    "### <font color=\"darkblue\"> MCMC - Overview\n",
    "\n",
    "- Samples are drawn from a simple proposal distribution.\n",
    "- Each draw depends only on the previous draw.\n",
    "- The resultant Markov Chain will have a stationary distribution.\n",
    "- The only requirement is that the target distribution needs to be proportional to the proposal distribution.\n",
    "- Correlated draws from the target distribution can be used.\n",
    "- In Bayesian analysis, the target is the posterior (up to the normalizing constant).\n",
    "\n",
    "Let us now discuss two methods that are essential tools for efficiently sampling from high-dimensional or complex distributions when direct sampling is infeasible. \n",
    "\n",
    "The **Metropolis-Hastings (MH)** algorithm is a general-purpose MCMC method that generates samples from a complex probability distribution. It works by proposing new samples and accepting or rejecting them based on a specific criterion. This algorithm is widely used beyond Bayesian statistics, applicable to any scenario where direct sampling from the target distribution is difficult.\n",
    "\n",
    "The **Gibbs sampler** is an MCMC method that iteratively samples each variable from its conditional distribution given the others. It is particularly useful when the conditional distributions are easy to sample from but the joint distribution is complex. The Gibbs sampler is commonly used in Bayesian inference for sampling from posterior distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593731e8-235f-41bc-9418-962ab0f4a338",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings (MH) Algorithm\n",
    "\n",
    "The **Metropolis-Hastings (MH)** algorithm is a Markov Chain Monte Carlo (MCMC) method used to generate samples from a probability distribution when direct sampling is difficult. The method relies on a proposal distribution to suggest new candidate samples and then uses an acceptance criterion to decide whether to accept or reject the candidate.\n",
    "\n",
    "### Key Steps:\n",
    "1. **Initialization:** Start with an initial state $x_0$.\n",
    "2. **Proposal Generation:** At each iteration, generate a candidate sample $x'$ from a proposal distribution $Q(x' | x)$, which depends on the current state $x$.\n",
    "3. **Acceptance Criterion:** Accept the new sample $x'$ with probability:\n",
    "   $$\n",
    "   \\alpha(x, x') = \\min\\left(1, \\frac{P(x') Q(x | x')}{P(x) Q(x' | x)}\\right)\n",
    "   $$\n",
    "   where $P(x)$ is the target distribution and $Q$ is the proposal distribution. If the candidate is not accepted, stay in the current state.\n",
    "4. **Repeat:** Repeat the process for a large number of iterations to generate a sequence of samples from the target distribution.\n",
    "\n",
    "The MH algorithm is particularly useful when the target distribution is complex, but the proposal distribution is easier to sample from.\n",
    "\n",
    "---\n",
    "\n",
    "### Gibbs Sampler\n",
    "\n",
    "The **Gibbs sampler** is another MCMC method used to generate samples from a multivariate distribution, where direct sampling is often intractable. It works by iteratively sampling each variable in the distribution conditional on the others, simplifying the sampling process.\n",
    "\n",
    "### Key Steps:\n",
    "1. **Initialization:** Start with an initial state for each variable $X_1, X_2, \\dots, X_d$.\n",
    "2. **Iterative Sampling:** In each iteration, sample each variable $X_i$ from its conditional distribution given the other variables. The conditional distribution $P(X_i | X_1, \\dots, X_{i-1}, X_{i+1}, \\dots, X_d)$ is computed based on the current values of the other variables.\n",
    "3. **Repeat:** Repeat the process for a large number of iterations, updating each variable conditionally on the others.\n",
    "\n",
    "The Gibbs sampler is particularly effective when the conditional distributions are easy to sample from, but the joint distribution is not. It is widely used in Bayesian inference for sampling from the posterior distribution.\n",
    "\n",
    "---\n",
    "\n",
    "Both the **Metropolis-Hastings** and **Gibbs sampler** are foundational methods in MCMC that allow for sampling from complex distributions, each with its own strengths and ideal use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da847b-ac3b-42d7-88e5-0bf735237e0d",
   "metadata": {},
   "source": [
    "## <font color=\"darkred\"> Handling MCMC\n",
    "\n",
    "MCMC involves generating a sequence of samples from a target distribution using a sampler (e.g., Metropolis-Hastings or Gibbs). The process starts with specifying initial values for the parameters, which should be chosen based on the parameter range. A burn-in period is used to discard the initial samples, allowing the chain to reach a stationary distribution. The number of chains and iterations should be sufficient to ensure proper exploration of the target distribution and reliable results.\n",
    "\n",
    "<font color=\"darkgreen\"> ***Initial values:***\n",
    "\n",
    "As we observed earlier, the initial value of $X_0$ must be specified for all unknowns (parameters of interest). The choice of initial value depends on the range of the parameter. For example, in a Beta-Binomial model where $0 < \\theta < 1$, the initial value for $\\theta$ must be chosen from the interval $(0,1)$. On the other hand, for the mean parameter in a Normal-Normal model, any value from $(-\\infty, +\\infty)$ can serve as the initial point.\n",
    "\n",
    "A practical consideration is what happens if we attempt different starting points for a parameter. \n",
    "\n",
    "***<font color=\"darkgreen\">C***: Number of Chains; a Markov chain for each of the initial values\n",
    "\n",
    "***<font color=\"darkgreen\">N***: Number of Simulations; which is length of sequence of sampling;\n",
    "\n",
    "***<font color=\"darkgreen\">B:*** Number of burn-ins; initial warm-up samples may be dropped\n",
    "\n",
    "***<font color=\"darkgreen\">T:*** Thin; length of the interval to pick values during sampling;\n",
    "\n",
    "**Then finally, generated sample will have**\n",
    "\n",
    "***<font color=\"darkgreen\">K:*** Number of samples = $\\mathrm{C}\\times\\frac{N-B}{T}$\n",
    "\n",
    "### <font color=\"darkblue\"> Final word\n",
    "\n",
    "<span style=\"color:blue\">MCMC samplers are computationally intensive because they require significant computing power for generating and evaluating large numbers of correlated samples. In addition to the core sampling process, tools like visual aids (e.g., trace plots) and diagnostics are often used to assess convergence, further adding to the computational demands. Efficient implementation and adequate computational resources are crucial for successfully running MCMC simulations, especially with complex models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
