{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\"> Bayes Theorem\n",
    "\n",
    "## **Bayes Theorem for the Discrete Case**\n",
    "\n",
    "In the discrete case, where the parameter $ \\theta $ takes discrete values, Bayes' Theorem can be derived from the **definition of conditional probability**.\n",
    "\n",
    "## **Statement of Bayes Theorem for the Discrete Case**\n",
    "\n",
    "Bayes' Theorem in the discrete case is given by:\n",
    "\n",
    "$$\n",
    "P(\\theta | \\text{X}) = \\frac{P(\\text{X} | \\theta) P(\\theta)}{P(\\text{X})}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ P(\\theta | \\text{X}) $ is the **posterior probability** of $ \\theta $ given the data.\n",
    "- $ P(\\text{X} | \\theta) $ is the **likelihood**, or the probability of observing the data given $ \\theta $.\n",
    "- $ P(\\theta) $ is the **prior probability** of $ \\theta $ before observing the data.\n",
    "- $ P(\\text{X}) $ is the **marginal likelihood**, which ensures that the posterior is a valid probability distribution. It is the sum of the likelihood times the prior over all possible values of $ \\theta $:\n",
    "\n",
    "$$\n",
    "P(\\text{X}) = \\sum_{\\theta} P(\\text{X} | \\theta) P(\\theta)\n",
    "$$\n",
    "\n",
    "### <font color=\"darkgreen\"> **Proof of Bayes Theorem (Discrete Case)**\n",
    "\n",
    "We start with the definition of **conditional probability**:\n",
    "\n",
    "$$\n",
    "P(\\theta | \\text{X}) = \\frac{P(\\theta \\cap \\text{X})}{P(\\text{X})}\n",
    "$$\n",
    "\n",
    "By the definition of joint probability, we know that:\n",
    "\n",
    "$$\n",
    "P(\\theta \\cap \\text{X}) = P(\\text{X} | \\theta) P(\\theta)\n",
    "$$\n",
    "\n",
    "Thus, substituting into the original equation, we get:\n",
    "\n",
    "$$\n",
    "P(\\theta | \\text{X}) = \\frac{P(\\text{X} | \\theta) P(\\theta)}{P(\\text{X})}\n",
    "$$\n",
    "\n",
    "This is the desired form of **Bayes' Theorem** in the discrete case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\">Understanding Bayesian Approach using Discrete Probabilities\n",
    "\n",
    "1. Parameter is a random variable\n",
    "\n",
    "1. Parametric values can be chosen arbitrarily (discretized for a continuous variable)\n",
    "\n",
    "1. Probable weights (prior probabiliteis) can be assigned to each of these values\n",
    "\n",
    "1. Compute the likelihood after observing the data for the above set of parametric values\n",
    "\n",
    "1. Find the posterior probabilites using Bayes Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\"> Example for Discrete case\n",
    "\n",
    "Assume that we are interested to find the probability that a city would receive rain on a given day, say Jan 15. From the earlier recorded data of 150 years, it was found that 23 years have recorded rain on Jan 15 (amount of rain fall is not considered). A team of experts have observed that the chances of a rain fall on Jan 15 would be as low as 1%, 5%, 10% and a maximum of 20%. Also, they have noted that the probabilities for the above four plausible values are 0.70, 0.20, 0.07, and 0.03 respectively. This may indicate that the experts might note a lower probability for 10% and 20% chance of rain. Based on these two information (sample data + experts' assessment) we can find the probability of a possible rain fall on Jan 5.\n",
    "\n",
    "## Solution\n",
    "\n",
    "### Prior:\n",
    "\n",
    "$\\theta = {0.01,  0.05, 0.10, 0.20}$ with respective probabilites $p(\\theta) = 0.70, 0.20, 0.07, 0.03$\n",
    "\n",
    "### Likelihood:\n",
    "\n",
    "Since the random variable is event of rainfall that has a binary outcome Yes / No and the parameter is proportion of success we would assume a Biomial distribution for this scenario\n",
    "\n",
    "$\\mathscr{L}(\\theta)=\\binom{n}{x} \\theta^x (1-\\theta)^{n-x}$ with $n = 150$ and $x = 23$\n",
    "\n",
    "For the different values of $\\theta$ let us calculate this \n",
    "\n",
    "1. For $\\theta = 0.01$, $P(\\text{X}|\\theta= 0.01) = \\binom{150}{23} 0.01^{23} (1-0.01)^{150-23} = 2.047 \\times 10^{-20}$\n",
    "\n",
    "2. For $\\theta = 0.05$, $P(\\text{X}|\\theta= 0.05) = \\binom{150}{23} 0.05^{23} (1-0.05)^{150-23} = 1.30 \\times 10^{-6}$\n",
    "\n",
    "3. For $\\theta = 0.10$, $P(\\text{X}|\\theta== 0.10) = \\binom{150}{23} 0.10^{23} (1-0.10)^{150-23} = 0.01133$\n",
    "\n",
    "4. For $\\theta = 0.20$, $P(\\text{X}|\\theta=0.20) = \\binom{150}{23} 0.20^{23} (1-0.20)^{150-23} = 0.03031$\n",
    "\n",
    "### Posterior\n",
    "\n",
    "$$P(\\theta | \\text{X}) = \\frac{P(\\text{X} | \\theta) P(\\theta)}{P(\\text{X})}$$\n",
    "\n",
    "First let us calculate the denominator term $P(\\text{X}) = \\sum_{\\theta} P(\\text{X} | \\theta) P(\\theta)$ using the above prior and likelihood values \n",
    "\n",
    "$$P(\\text{X})=(0.70)(2.047 \\times 10^{-20})+90.20)(1.30 \\times 10^{-6})+(0.07)(0.01133)+(0.03)(0.03031) = 0.00170266$$\n",
    "\n",
    "Hence,\n",
    "\n",
    "1. For $\\theta = 0.01$, $P(\\theta|\\text{X}) = \\frac{(0.70)(2.047 \\times 10^{-20})}{0.00170266} = 8.416 \\times 10^{-18}$\n",
    "\n",
    "In a similar way we shall calculate $P(\\theta|\\text{X})$ for other values of $\\theta = 0.05, 0.1, 0.2$ and the posterior probabilities are\n",
    "\n",
    "0.00015 $(\\theta = 0.05)$\n",
    "\n",
    "0.4658  $(\\theta = 0.1)$\n",
    "\n",
    "0.5340  $(\\theta = 0.2)$\n",
    "\n",
    "From these posterior we could observe that data $(x = 23 n = 150)$ has been used to update the prior beliefs\n",
    "\n",
    "Prior belief was rain fall on Jan 15 might be rare (probability for 1% chance of rain fall was higher 0.70)\n",
    "\n",
    "But posterior probability indicates that there could be 10 to 20 % chance for the rain fall which is drawn from the higher posterior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tTRR-MOFoGH"
   },
   "source": [
    "# <font color=\"darkblue\"> Revisit the Practical Scenario\n",
    "\n",
    "[Honda Vs Hero](https://auto.economictimes.indiatimes.com/news/two-wheelers/motorcycles/honda-disputes-hero-splendor-ismarts-fuel-economy-claim-of-102-5-km/litre/47139285)\n",
    "\n",
    "**Japanese auto maker Honda has questioned its erstwhile Indian partner Hero's claim of <font color=\"red\">102.5 km/litre </font> fuel economy rate for Splendor iSmart bike, saying \"such claims are misleading and are far from reality\".**\n",
    "\n",
    "\n",
    "<font color=\"green\">**The Indian firm, Hero MotoCorp on its part hit back saying its fuel efficiency values were certified by iCAT (International Centre for Automotive Technology)**\n",
    "\n",
    "CAT may test mileage of the bikes of the same brand\n",
    "\n",
    "Output would be the mileage in <font color=\"red\">---- km/litre </font> for each bike\n",
    "\n",
    "We may be interested to test the claim in an analytical manner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkdfKIHZIEIZ"
   },
   "source": [
    "# <font color=\"darkblue\"> Possible Metrics\n",
    "\n",
    "1.   Number of bikes having the mileage as per Hero's claim out of a batch of bikes to test\n",
    "\n",
    "1.   Number of bikes having the mileage as per Hero's claim from an unknown number of bikes to be tested (CAT may decide)\n",
    "\n",
    "1.   Average mileage from an arbitrary number of bikes to be tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fUFBIh-XQCmS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "from scipy import stats as st\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mAvPWj3RQWKj"
   },
   "source": [
    "# <font color=\"darkblue\"> Data Type I\n",
    "\n",
    "Batch size known, say $n = 100$\n",
    "\n",
    "Looking for the **number** of bikes have passed the test, say $x = 35$\n",
    "\n",
    "So underlying data distribution is Binomial$(n,\\theta)$ and the aim is to estimate (getting the inference) the parameter $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "mCBjNCdmQFAe",
    "outputId": "dc65c6be-4cf8-4780-b794-969050209fac"
   },
   "outputs": [],
   "source": [
    "theta=np.array([0.1,0.4, 0.5,0.75, 0.9])\n",
    "prior_theta=np.array([0.01,0.02,0.52,0.2,0.25])\n",
    "\n",
    "n=100\n",
    "x=35\n",
    "\n",
    "likel_b=st.binom.pmf(x,n,theta)\n",
    "\n",
    "poste_theta=likel_b*prior_theta/sum(likel_b*prior_theta)\n",
    "poste_theta=np.round(poste_theta,3)\n",
    "\n",
    "r1=pd.concat([pd.DataFrame(theta),pd.DataFrame(prior_theta),pd.DataFrame(poste_theta)],axis=1)\n",
    "r1.columns=[\"Parameter\",\"Prior\",\"Posterior\"]\n",
    "print(r1.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 10))\n",
    "plt.plot(theta, poste_theta, 'x--', label= 'Posterior')\n",
    "plt.plot(theta, prior_theta, 'o-', label= 'Prior')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qx_rFjXsQpWO"
   },
   "source": [
    "# <font color=\"darkblue\"> Data Type II\n",
    "\n",
    "**Number** of bikes passed the test assuming that as many bikes could be tested\n",
    "\n",
    "Typically we are interested to estimate average number of bikes that have passed the test\n",
    "\n",
    "Here,it is a count model and we would model this with Poisson distribution to estimate $Pr(\\theta|\\text{X})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9g22-4lcQL_H",
    "outputId": "7ec78ded-2658-4ff8-96b3-6b91159b7fb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Parameter  Prior  Posterior\n",
      "        30   0.40      0.000\n",
      "        40   0.25      0.068\n",
      "        50   0.18      0.473\n",
      "        60   0.17      0.459\n"
     ]
    }
   ],
   "source": [
    "theta=np.array([30, 40, 50,60])\n",
    "prior_theta=np.array([0.4,0.25,0.18,0.17])\n",
    "\n",
    "x=st.randint.rvs(low=30,high=100,size=1)\n",
    "\n",
    "likel_p=st.poisson.pmf(x,theta)\n",
    "\n",
    "poste_theta=likel_p*prior_theta/sum(likel_p*prior_theta)\n",
    "poste_theta=np.round(poste_theta,3)\n",
    "\n",
    "r2=pd.concat([pd.DataFrame(theta),pd.DataFrame(prior_theta),pd.DataFrame(poste_theta)],axis=1)\n",
    "r2.columns=[\"Parameter\",\"Prior\",\"Posterior\"]\n",
    "print(r2.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yryt9Z4wQyAZ"
   },
   "source": [
    "# <font color=\"darkblue\"> Data Type III\n",
    "\n",
    "**Average Mileage** of a batch of bikes passed the test\n",
    "\n",
    "Batch size pre-defined\n",
    "\n",
    "Since we are trying to model a numeric variable (**Average Mileage**) we could use a Normal distribution with parameters $\\theta, \\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FWd5OdFnQPb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Parameter  Prior  Posterior\n",
      "    104.54   0.40      0.017\n",
      "     99.10   0.15      0.144\n",
      "     99.70   0.10      0.290\n",
      "     99.71   0.18      0.531\n",
      "    104.26   0.17      0.018\n"
     ]
    }
   ],
   "source": [
    "t1=[104.54,  99.10 ,  99.70,  99.71, 104.26] #Mileage - plausible values\n",
    "theta=np.array(t1)\n",
    "prior_theta=np.array([0.4,0.15,0.1,0.18,0.17])\n",
    "\n",
    "x=101.25 #Observed average mileage\n",
    "\n",
    "likel_n=st.norm.pdf(x,theta)\n",
    "\n",
    "poste_theta=likel_n*prior_theta/sum(likel_n*prior_theta)\n",
    "poste_theta=np.round(poste_theta,3)\n",
    "\n",
    "r3=pd.concat([pd.DataFrame(theta),pd.DataFrame(prior_theta),pd.DataFrame(poste_theta)],axis=1)\n",
    "r3.columns=[\"Parameter\",\"Prior\",\"Posterior\"]\n",
    "print(r3.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
