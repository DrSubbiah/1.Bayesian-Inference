{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea1f6c68-91c4-40a2-a63e-e0b2c8e75aec",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\"> Poisson Gamma Model\n",
    "\n",
    "The Poisson distribution is a statistical model used to describe the probability of a given number of events happening in a fixed interval of time or space, given that these events occur with a known constant mean rate and independently of the time since the last event. It is particularly useful when events are rare but can happen any number of times within the given interval.\n",
    "\n",
    "**Examples**\n",
    "\n",
    "1. Calls to a Call Center: \n",
    "Imagine a call center that receives, on average, 20 calls per hour. The Poisson distribution can be used to model the number of calls that the center receives in a given hour. For example, if the management wants to calculate the probability of receiving exactly 25 calls in an hour, they can apply the Poisson distribution. \n",
    "\n",
    "2. Arrival of Customers at a Coffee Shop:\n",
    "Consider a coffee shop where, on average, 15 customers arrive per hour. The Poisson distribution can model the probability of having exactly 10 customers within an hour. By applying the Poisson model, the coffee shop owner can understanf customer traffic patterns, adjust staff schedules, and optimize the customer service process, particularly during peak hours.\n",
    "\n",
    "3. Accidents in a Hospital Emergency Room:\n",
    "In a hospital emergency room, it is known that, on average, 5 emergency cases arrive per hour. The Poisson distribution can be used to estimate the probability of receiving a specific number of emergency cases in a given hour. For example, the hospital might want to determine the probability of exactly 3 emergency patients arriving within an hour, helping them plan staffing and resource allocation more effectively.\n",
    "\n",
    "4. Rare Earthquake Events in a Region:\n",
    "Suppose a particular region experiences, on average, 1 earthquake every 5 years. This makes earthquakes relatively rare, but they still occur with a known average rate. The Poisson distribution could be used to estimate the probability of having exactly 2 earthquakes in a given year. Here, the events (earthquakes) are rare occurrences over a fixed period of time, which fits the characteristics of a Poisson process.\n",
    "\n",
    "5. Rare Disease Diagnoses:\n",
    "Imagine a hospital in a large city where, on average, only 2 cases of a rare disease are diagnosed each month. Given this low occurrence, the Poisson distribution could be used to predict the likelihood of diagnosing exactly 3 cases in a particular month. The rarity of the disease makes this scenario a good candidate for a Poisson distribution.\n",
    "\n",
    "---\n",
    "\n",
    "Consider $n$ independent and identically distributed (**i.i.d.**) Poisson random variables $Y_1, Y_2, \\dots, Y_n$\n",
    "\n",
    "$$\n",
    "Y_i \\sim \\text{Poisson}(\\theta), \\quad \\theta \\in (0, \\infty) \\quad  Y_i \\in \\{0,1,2,\\cdots \\cdots \\cdots\\}$$ \n",
    "\n",
    "Hence the range of $Y$ is $\\mathscr{A}_Y = \\{0,1,2,\\cdots \\cdots \\cdots\\}$ and that of the parameter $\\theta$ is $(0,\\infty)$ or equivalently $0 < \\theta < \\infty$\n",
    "\n",
    "Each $Y_i$ takes values in with probability mass function:\n",
    "\n",
    "$$P(Y_i = y_i \\mid \\theta) = \\frac{e^{-\\theta} ~ \\theta^{ y_i}}{y_i !}$$\n",
    "\n",
    "Also, if $X= \\sum_{i=1}^{n} y_i$  represents the number of occurances of the event, then $X$ follows a Poisson distribution with parameter $n ~\\theta$\n",
    "\n",
    "Then the Probability Mass Funtion (PMF) of $X|\\theta$ is\n",
    "\n",
    "$$P(X = x \\mid \\theta) = \\frac{e^{-n\\theta} ~ (n\\theta)^{x}}{x!}$$\n",
    "\n",
    "---\n",
    "\n",
    "In the context of occurance of an event (rare), Bayesian statistical inference aims to estimate the proportion of average occurance in a population, given a sample. Using Bayes' theorem, prior beliefs about the average are updated with observed data to produce a posterior distribution, capturing uncertainty and incorporating prior knowledge into the estimate.\n",
    "\n",
    "Let us consider a **conjugate prior** for this parameter whose space is $\\mathscr{A}_{\\theta}=(0, \\infty)$, a continuous random variable in the positive real line.  The **Gamma distribution** is a natural choice for modeling the **average occurances** in a Bayesian context\n",
    "\n",
    "---\n",
    "\n",
    "## <font color=\"darkgreen\"> **Likelihood Function**\n",
    "\n",
    "Given $n$ observations, the likelihood function of $\\theta$  is \n",
    "$$\\mathscr{L}(\\theta)=\\frac{e^{-n\\theta} ~ (n\\theta)^{x}}{x!}$$\n",
    "\n",
    "## <font color=\"darkblue\"> **Gamma Prior for $\\theta$**\n",
    "\n",
    "Assume a **Gamma prior** distribution for the parameter $\\theta$:\n",
    "\n",
    "$$\n",
    "\\theta \\sim \\text{Gamma}(a, b)\n",
    "$$\n",
    "\n",
    "The Probability Density Function (PDF) of a Gamma distribution is:\n",
    "\n",
    "$$\n",
    "P(\\theta) = \\frac{1}{\\Gamma{a}b^a} \\theta^{a-1} ~ e^{-\\frac{\\theta}{b}} \n",
    "$$\n",
    "\n",
    "where $\\Gamma{a}$ is the **Gamma function** = $\\int_0^{\\infty} e^{-t}~ t^{a-1} ~dt$:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1c16db-a809-4eb6-b14a-73d6fdf6fb47",
   "metadata": {},
   "source": [
    "## <font color=\"darkblue\"> **Posterior Distribution via Bayes' Theorem**\n",
    "\n",
    "Applying Bayes' theorem:\n",
    "\n",
    "$$\n",
    "\\pi(\\theta \\mid \\mathbf{X}) = \\frac{\\mathscr{L}(\\theta) \\, P(\\theta)}{m(\\mathbf{X})}$$ where $m(\\mathbf{X})$ is called the marginal likelihood\n",
    "\n",
    "The denominator is \n",
    "\n",
    "$$m(\\mathbf{X}) = \\int_0^{\\infty} \\frac{1}{\\Gamma{a}\\,b^a} \\theta^{a-1} ~ e^{-\\frac{\\theta}{b}}\\, \\frac{e^{-n\\theta} ~ (n\\theta)^{x}}{x!}d\\theta$$\n",
    "\n",
    "$$=\\frac{n^x}{x!\\,\\Gamma{a}\\,b^a}\\int_0^{\\infty}  \\theta^{x+a-1} ~ e^{-\\theta(n+\\frac{1}{b})} \\,d\\theta$$\n",
    "\n",
    "Let $(n+\\frac{1}{b})\\theta \\,= \\,t$ so that $(n+\\frac{1}{b}) d\\theta\\,= \\,dt$ and hence \n",
    "\n",
    "$$m(\\mathbf{X}) = \\frac{1}{(n+\\frac{1}{b})^{x+a}}\\frac{n^x}{x!\\,\\Gamma{a}\\,b^a}\\int_0^{\\infty} t^{x+a-1} \\,e^{-t} \\, dt$$\n",
    "\n",
    "$$ \\implies m(\\mathbf{X}) = \\frac{1}{(n+\\frac{1}{b})^{x+a}}\\frac{n^x}{x!\\,\\Gamma{a}\\,b^a} \\, \\Gamma{(x+a)}$$ using the definition of Gamma Integral\n",
    "\n",
    "Hence, the posterior distribution of $\\theta$ is \n",
    "\n",
    "\n",
    "$$\n",
    "\\pi(\\theta \\mid \\mathbf{X}) = \\frac{\\frac{n^x}{x!\\,\\Gamma{a}\\,b^a}  \\theta^{x+a-1} ~ e^{-\\theta(n+\\frac{1}{b})} }{\\frac{1}{(n+\\frac{1}{b})^{x+a}}\\frac{n^x}{x!\\,\\Gamma{a}\\,b^a} \\, \\Gamma{(x+a)}}$$\n",
    "\n",
    "$\\implies$\n",
    "\n",
    "$$\n",
    "\\pi(\\theta \\mid \\mathbf{X}) = \\frac{1}{\\Gamma(x+a)(\\frac{1}{n+\\frac{1}{b}})^{x+a}} \\, {\\theta^{x+a-1} ~ e^{-(n+\\frac{1}{b})}\\theta}$$\n",
    "\n",
    "$\\implies$\n",
    "\n",
    "$$\n",
    "\\pi(\\theta \\mid \\mathbf{X}) = \\frac{1}{\\Gamma(x+a)(\\frac{1}{n+\\frac{1}{b}})^{x+a}} \\, {\\theta^{x+a-1} ~ e^{-\\frac{\\theta}{\\frac{1}{n+\\frac{1}{b}}}}}$$\n",
    "\n",
    "This is a Gamma Distribution with shape parameter $x+a$ and scale parameter $\\frac{1}{n+\\frac{1}{b}}$\n",
    "\n",
    "### <font color=\"darkblue\"> **Final Notes**\n",
    "\n",
    "- The **posterior distribution** is a Gamma distribution.\n",
    "  \n",
    "- The **updated parameters** are:\n",
    "  - **Posterior shape parameter**: $a' = x + a$\n",
    "  - **Posterior rate parameter**: $b' = \\frac{1}{n+\\frac{1}{b}}$\n",
    "    \n",
    "- This demonstrates that the **Gamma distribution is a conjugate prior** for the parameter (average number of occurances) in the Poisson likelihood.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## <font color=\"darkred\">**Point Estimate from the Posterior Beta distribution**\n",
    "\n",
    "The shape and scale parameters of the posterior Gamma distribution are \n",
    "\n",
    "- $ a' = x + a $ \n",
    "- $ b' = \\frac{1}{n+\\frac{1}{b}}$\n",
    "\n",
    "### MAP \n",
    "\n",
    "The **MAP estimate** corresponds to the mode of the posterior distribution. For a **Gamma distribution**, the mode is given by:\n",
    "\n",
    "$$\\hat{\\theta}_{MAP} = (a'-1)\\times b'$$ provided $a'>1$\n",
    "\n",
    "\n",
    "### Mean:\n",
    "\n",
    "$$\\text{E}[\\theta \\mid \\mathbf{X}] = a'\\times b'$$\n",
    "\n",
    "### Variance:\n",
    "\n",
    "$$\\text{Var}[\\theta \\mid \\mathbf{X}] = a' \\times (b')^2$$\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
